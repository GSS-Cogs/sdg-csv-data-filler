{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from yaml import safe_load\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "sdg-csv-data-filler is the first module in a data pipeline to take\n",
    "data from the SDG data repo and make it exportable as CSVW.\n",
    "\"\"\"\n",
    "\n",
    "# setting paths to directories and files\n",
    "remote_data_url = \"https://github.com/ONSdigital/sdg-data/tree/develop/data\"\n",
    "cwd = os.getcwd()\n",
    "data_path = os.path.join(cwd, 'data')\n",
    "out_path = os.path.join(cwd, 'out')\n",
    "gap_filler_yam_path = (os.path.join\n",
    "                       (\"substitutions\",\n",
    "                        \"gap_filler.yaml\"))\n",
    "header_mapping_yam_path = (os.path.join\n",
    "                           (\"substitutions\",\n",
    "                            \"header_mapping.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_dicts(path_to_yaml):\n",
    "    \"\"\"\n",
    "    Loads dictionaries for the gap filling and mapping of column names \n",
    "    from locally stored .yaml files\n",
    "    \n",
    "        Parameters:\n",
    "            gap_filler_yaml (string): Path to the yaml file storing the values\n",
    "                to fill gaps with in each column\n",
    "            header_mapping_yaml (string): Path to the yaml file storing the \n",
    "                names to change headers to for each column\n",
    "        Returns:\n",
    "            dict: dict_from_yam\n",
    "            \n",
    "    \"\"\"\n",
    "    with open(path_to_yaml) as file:\n",
    "        dict_from_yam = safe_load(file)\n",
    "    \n",
    "    return dict_from_yam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_urls(url):\n",
    "    \"\"\"\n",
    "    Provided with a data folder URL, this function finds the URLS\n",
    "    of the CSV files within the folder. A generator is yielded with\n",
    "    the links of all files in the folder.\n",
    "        Parameters:\n",
    "            url (string): the URL of the repo/folder which contains\n",
    "                the CSV files to be captured\n",
    "        Yields:\n",
    "            string: generator, the next URL for the CSV file in the \n",
    "            remote data folder \n",
    "    \"\"\"\n",
    "    page = requests.get(url, verify=False) #proxies=proxies\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "    csv_link_pattern = r\"\\/ONSdigital\\/sdg-data\\/blob\\/develop\\/data\\/indicator_\\d-\\d{1,2}-\\d{1,2}\\.csv\"\n",
    "    to_repl_pattern = r\"\\/sdg-data\\/blob\\/develop\"\n",
    "    replacement_pattern = \"/sdg-data/develop\"\n",
    "    list_of_links = []\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(csv_link_pattern)}):\n",
    "        link = link.get('href')\n",
    "        link = re.sub(to_repl_pattern, replacement_pattern, link)\n",
    "        yield (\"https://raw.githubusercontent.com\"+link)\n",
    "        # Alternative to return a list\n",
    "        # list_of_links.append(\"https://raw.githubusercontent.com\"+link)\n",
    "    # return list_of_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvs_to_pandas(url):\n",
    "    \"\"\"\n",
    "    Provided with a URL of a file, the fucntion will check if the CSV\n",
    "    is populated and if not empty return a Pandas dataframe of the CSV\n",
    "        Parameters:\n",
    "            url (string): the URL of a CSV file to be captured\n",
    "        Returns:\n",
    "            pd.DataFrame: a Pandas dataframe of the CSV\n",
    "    \"\"\"\n",
    "    if \"no data for this indicator yet\" in str(bs(requests.get(url).text)):\n",
    "        return None\n",
    "    else:\n",
    "        return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvsample_to_pandas(path_to_file, pct=1.0):\n",
    "    \"\"\"\n",
    "    A function to create a sample extract of a csv as a dataframe\n",
    "    \n",
    "        Parameters:\n",
    "            path_to_file (string): full path to csv file\n",
    "            p (float): decimal amount of lines to extract\n",
    "            \n",
    "        Returns:\n",
    "            pd.Dataframe\n",
    "            \"\"\"\n",
    "    p = pct/100  \n",
    "    # keep the header, then take only 1% of lines\n",
    "    # if random from [0,1] interval is greater than 0.01 the row will be skipped\n",
    "    df = pd.read_csv(\n",
    "             path_to_file,\n",
    "             header=0, \n",
    "             skiprows=lambda i: i>0 and random.random() > p)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gaps(pd_df, gap_filler_dict):\n",
    "    \"\"\"\n",
    "    Given a Pandas dataframe and a dictionary containing the column names\n",
    "    the correct 'fillers' for each column, this function will fill\n",
    "    each column with the correct values when empty cells are found.\n",
    "        Parameters:\n",
    "            pd_df (pd.Dataframe): the variable to which the dataframe \n",
    "                containing the csv data is assigned\n",
    "            gap_filler_dict (dict): a dictionary with column name and value \n",
    "                to fill gaps as key value pairs, e.g.\n",
    "                {\"Age\":\"All\",\"Sex\":\"T\"}\n",
    "        Returns:\n",
    "            pd.Dataframe: A dataframe with all cells full\"\"\"\n",
    "    df = pd_df.fillna(gap_filler_dict, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_cell_values(pd_df, dict_of_nonstandard_standard):\n",
    "    \"\"\"\n",
    "    Maps non-standard values e.g. \"Males\" to standard values like \"M\".\n",
    "    Mapping is carried out on a column-specific basis.\n",
    "    \"\"\"\n",
    "    df = (pd_df.replace\n",
    "          (to_replace=dict_of_nonstandard_standard,\n",
    "          value=None))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_headers(pd_df, dict_of_nonstandard_standard):\n",
    "    \"\"\"\n",
    "    Changes the non-standard CSV column headers to harmonised-data \n",
    "    column headers. \n",
    "    e.g. 'Age Group' to 'Age'\n",
    "    \"\"\"\n",
    "    # Do whitespaces need to be replaced with underscores?\n",
    "    col_names = list(pd_df.columns)\n",
    "    correction_dict = ({col_nm: col_nm.strip().title() \n",
    "                        for col_nm in col_names})\n",
    "    df = pd_df.rename(columns=correction_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(pd_df, out_path):\n",
    "    \"\"\"\n",
    "    Converts a Pandas dataframe to CSV and writes it out to a local folder.\n",
    "        Parameters:\n",
    "            pd_df (pd.Dataframe): The pandas data frame of the data\n",
    "            path (string): the path of the local \"out\" folder\n",
    "        Returns:\n",
    "            Boolean: True is written, False if not written \"\"\" \n",
    "    status = True\n",
    "\n",
    "    # If the csv dir isn't there, make it\n",
    "    csv_dir = out_path\n",
    "    if not os.path.exists(csv_dir):\n",
    "        os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        df.to_csv(csv_dir, index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "    return status                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def entry_point(data_url):\n",
    "#     urls_gen = find_csv_urls(data_url)\n",
    "#     gap_filler_dict = (get_mapping_dicts(gap_filler_yam_path) \n",
    "#     header_mapping_dict = (get_mapping_dicts(header_mapping_yam_path))\n",
    "\n",
    "#     for _url in urls_gen:\n",
    "#         data_name = extract_name(_url)\n",
    "#         df = csvs_to_pandas(_url)\n",
    "#         if not df:\n",
    "#             continue\n",
    "#         df = fill_gaps(df, gap_filler_dict)\n",
    "#         df = standardise_headers(df)\n",
    "#         write_csv(df, out_path)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     entry_point(data_url=remote_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_random_values(df, holes=20):\n",
    "    \"\"\"\n",
    "    Smashes holes in your dataframe to the approximate number that you\n",
    "    request (randint might choose the same cell twice)\n",
    "    \"\"\"\n",
    "    for i in range(holes):\n",
    "        row = random.randint(1, df.shape[0]-1)\n",
    "        col = random.randint(0, df.shape[1]-1)\n",
    "        df.iloc[row, col] = float('nan')\n",
    "    return df\n",
    "\n",
    "def messup_headers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_yam_path = os.path.join(os.getcwd(), \"substitutions\", \"samp_filler.yaml\")\n",
    "csv_path = os.path.join(os.getcwd(), \"data\", \"indicator_9-1-1.csv\")\n",
    "dict_of_nonstandard_standard_path = (os.path.join(os.getcwd(),\n",
    "                                                  \"substitutions\",\n",
    "                                                  \"test_dict_of_nonstandard_standard.yaml\"))\n",
    "\n",
    "def proof_of_concept(csv_path,\n",
    "                     ns=dict_of_nonstandard_standard_path, \n",
    "                     path=test_yam_path):\n",
    "    # Creating a sample df. This is in place of csvs_to_pandas\n",
    "    samp_df = csvsample_to_pandas(path_to_file=csv_path, pct=1)\n",
    "    # Testing get_mapping_dicts func. Creating filler dictioary\n",
    "    samp_filler_dict = get_mapping_dicts(path)\n",
    "    # Creating dictionary to map non-standard terms with standard ones. \n",
    "    nonstandard_standard = get_mapping_dicts(ns)\n",
    "    # Creating gaps in the data (this will not be used in production)\n",
    "    holey_df = delete_random_values(samp_df)\n",
    "    # Testing that the filler dict works\n",
    "    refilled_df = holey_df.fillna(value=samp_filler_dict)\n",
    "    # Testing that standardise dict dills gaps as expected\n",
    "    samp_df = standardise_cell_values(refilled_df, nonstandard_standard)\n",
    "    standardise_headers\n",
    "    return samp_df\n",
    "\n",
    "poc_df = proof_of_concept(csv_path, path=test_yam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Local Authority</th>\n",
       "      <th>Road category</th>\n",
       "      <th>Observation status</th>\n",
       "      <th>Unit multiplier</th>\n",
       "      <th>Unit measure</th>\n",
       "      <th>GeoCode</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>Blackpool</td>\n",
       "      <td>yellow brick road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>E06000009</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>Gravesham</td>\n",
       "      <td>yellow brick road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>E07000109</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>Salford</td>\n",
       "      <td>yellow brick road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>E08000006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Highway to hell</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>E07000042</td>\n",
       "      <td>28.590365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>Mowbry</td>\n",
       "      <td>Highway to hell</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>E07000133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>Halton</td>\n",
       "      <td>A-road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>infinity</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>E06000006</td>\n",
       "      <td>82.302495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>Swale</td>\n",
       "      <td>A-road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>fourty two</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>Preston</td>\n",
       "      <td>A-road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>Here be treasure</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yellow brick road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>E07000155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>knives and forks!</td>\n",
       "      <td>yellow brick road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>Here be treasure</td>\n",
       "      <td>36.978370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>whole world</td>\n",
       "      <td>Hart</td>\n",
       "      <td>Classified road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>infinity</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>fourty two</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>forever</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>ford for Oxen!</td>\n",
       "      <td>Classified road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>fourty two</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>Central Bedfordshire</td>\n",
       "      <td>Unclassified road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>E06000056</td>\n",
       "      <td>99.795863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Englandshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unclassified road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>fourty two</td>\n",
       "      <td>99.608828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>whole world</td>\n",
       "      <td>Craven</td>\n",
       "      <td>Unclassified road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>fourty two</td>\n",
       "      <td>99.423573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9 years ago</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Newport</td>\n",
       "      <td>yellow brick road</td>\n",
       "      <td>Uuunm-defined</td>\n",
       "      <td>PunkPundits</td>\n",
       "      <td>pashetaage!</td>\n",
       "      <td>W06000022</td>\n",
       "      <td>99.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year       Country       Local Authority      Road category  \\\n",
       "0   9 years ago  Englandshire             Blackpool  yellow brick road   \n",
       "1   9 years ago  Englandshire             Gravesham  yellow brick road   \n",
       "2   9 years ago  Englandshire               Salford  yellow brick road   \n",
       "3   9 years ago  Englandshire                   NaN    Highway to hell   \n",
       "4   9 years ago  Englandshire                Mowbry    Highway to hell   \n",
       "5   9 years ago  Englandshire                Halton             A-road   \n",
       "6   9 years ago  Englandshire                 Swale             A-road   \n",
       "7   9 years ago  Englandshire               Preston             A-road   \n",
       "8   9 years ago  Englandshire                   NaN  yellow brick road   \n",
       "9   9 years ago  Englandshire     knives and forks!  yellow brick road   \n",
       "10  9 years ago   whole world                  Hart    Classified road   \n",
       "11      forever  Englandshire        ford for Oxen!    Classified road   \n",
       "12  9 years ago  Englandshire  Central Bedfordshire  Unclassified road   \n",
       "13  9 years ago  Englandshire                   NaN  Unclassified road   \n",
       "14  9 years ago   whole world                Craven  Unclassified road   \n",
       "15  9 years ago         Wales               Newport  yellow brick road   \n",
       "\n",
       "   Observation status Unit multiplier Unit measure           GeoCode  \\\n",
       "0       Uuunm-defined     PunkPundits  pashetaage!         E06000009   \n",
       "1       Uuunm-defined     PunkPundits  pashetaage!         E07000109   \n",
       "2       Uuunm-defined     PunkPundits  pashetaage!         E08000006   \n",
       "3       Uuunm-defined     PunkPundits  pashetaage!         E07000042   \n",
       "4       Uuunm-defined     PunkPundits  pashetaage!         E07000133   \n",
       "5       Uuunm-defined        infinity  pashetaage!         E06000006   \n",
       "6       Uuunm-defined     PunkPundits  pashetaage!        fourty two   \n",
       "7       Uuunm-defined     PunkPundits  pashetaage!  Here be treasure   \n",
       "8       Uuunm-defined     PunkPundits  pashetaage!         E07000155   \n",
       "9       Uuunm-defined     PunkPundits  pashetaage!  Here be treasure   \n",
       "10      Uuunm-defined        infinity  pashetaage!        fourty two   \n",
       "11      Uuunm-defined     PunkPundits  pashetaage!        fourty two   \n",
       "12      Uuunm-defined     PunkPundits  pashetaage!         E06000056   \n",
       "13      Uuunm-defined     PunkPundits  pashetaage!        fourty two   \n",
       "14      Uuunm-defined     PunkPundits  pashetaage!        fourty two   \n",
       "15      Uuunm-defined     PunkPundits  pashetaage!         W06000022   \n",
       "\n",
       "         Value  \n",
       "0   100.000000  \n",
       "1   100.000000  \n",
       "2          NaN  \n",
       "3    28.590365  \n",
       "4     0.000000  \n",
       "5    82.302495  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9    36.978370  \n",
       "10  100.000000  \n",
       "11  100.000000  \n",
       "12   99.795863  \n",
       "13   99.608828  \n",
       "14   99.423573  \n",
       "15   99.990000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
